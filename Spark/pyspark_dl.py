# -*- coding: utf-8 -*-
"""Pyspark_dl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uETuGsDOznQwo9-r6113oftz8rg01WJa
"""

pip install pyspark

import pyspark

from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler, MinMaxScaler
from pyspark.ml.classification import MultilayerPerceptronClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

spark = SparkSession.builder.master('local').appName('dl').getOrCreate()

df = spark.read.csv('data_banknote_authentication.csv', header =True)

df.show(5)

df.printSchema()

for col in df.columns:
  df =df.withColumn(col,df[col].cast('double'))

df.printSchema()

# input colmn
input_cols = df.columns[:-1]

df.select(input_cols).show()

from pyspark.ml.feature import Imputer, MinMaxScaler

imputed_col = ['f_{}'.format(i+1) for i in range(4)]

imputed_col

model = Imputer(strategy = 'mean', missingValue=None, inputCols=input_cols,outputCols=imputed_col).fit(df)

impute_data = model.transform(df)

impute_data.show()

assemble = VectorAssembler(inputCols=imputed_col, outputCol='assembled_features')

a_data = assemble.transform(impute_data)

a_data.show(5)

scaler = MinMaxScaler(min=0.0, max=1.0,inputCol='assembled_features',outputCol='features')

s_data = scaler.fit(a_data).transform(a_data)

s_data.select('features').show(6)

s_data = s_data.withColumnRenamed('Class','label')

df.columns

a = ['Class','features']
s_data.show()

# cross validation
train_df, test_df = s_data.select('Class ','features').randomSplit([0.75,0.25],seed=0)

train_df.count()

test_df.count()

mlpc=MultilayerPerceptronClassifier(featuresCol='features',labelCol='Class ',
                                    layers =[4,6,12],maxIter=500,blockSize=8,seed=0,solver='gd')

ann = mlpc.fit(train_df)

pred = ann.transform(test_df)

evaluator = MulticlassClassificationEvaluator(labelCol='Class ',predictionCol='prediction',
                                              metricName='accuaracy')

